# Discussion 3/11/2025 (Continue developing)

## Key Points
- The primary focus is the estimation and inference for $\beta(t)$. For the theory part, the key result is consistency and convergence rate of $\hat{\beta}(t)$.
- Do not include penalty in the theory part. Then include penalty in the computation algorithm.
- Do not estimate $b_i(t)$ as it requires dense individual observations.
- Try multiplier bootstrap to estimate the covariance function of $\hat{\beta}(t)$. If the simulation results are good, then study the consistency of the covariance estimator.
- Find newer data on UCI.

---

## 1 Notation

- $Y(t)$: outcome process
- $X(t)$: a $d$-vector of potentially time-dependent covariates
- $N(t)$: counting process recording the number of observations
- $C$: follow-up time
- Use overline to denote the history, e.g., $\overline{N}(t) = \{N(s) : s \in [0,t]\}$
- Observed data up to time $t$

- $\mathcal{F}_t$: filtration generated by $\{\overline{Y}(t), \overline{N}(t-), \overline{X}(t)\}$

Consider a random sample of $n$ subjects, we use subscript $i$ to denote the above variables of the $i$ th subject $(i = 1, \ldots, n)$.

---

## 2 Models

### Varying coefficient model for the outcome process $Y(t)$

where:
- $\beta(t)$ is a vector of unknown functions of $t$
- $b(t)$ is a latent stochastic process accounting for the within-curve dependence
- $\epsilon(t)$ is the measurement error

We assume that:
- $X(t)$ contains the constant 1
- $b(t)$ has mean zero and covariance function $\xi(s,t)$
- $\epsilon(t)$ has mean zero and covariance function $\sigma^2(t)I(s = t)$
- $b(t)$ and $\epsilon(t)$ are independent

- Proportional intensity model for the conditional intensity function of $N(t)$ given $\overline{O}(t-)$

where:
- $\lambda_0(t)$ is an arbitrary baseline intensity function
- $\gamma$ is a set of unknown parameters
- $g(\cdot)$ is a set of prespecified functions of $\overline{O}(t-)$

---

## 3 Assumptions

(i) $E\{dN(t)|F_t\} = E\{dN(t)|\overline{O}(t-)\}$.

(ii) The conditional density of $C$ at time $t$ given $\{Y(\cdot), X(\cdot), b(\cdot)\}$ depends only on $\overline{X}(t)$ and is noninformative about the unknown parameters in models (1) and (2).

---

## 4 Methods

### 4.1 Inverse intensity weighting and identifiability

### 4.2 Estimation of weights

### 4.3 Estimation of varying coefficient functions

### 4.4 Inference on varying coefficient functions

---

## 5 Asymptotic properties

- **Estimators of varying coefficient functions:**
  - Bias of $\hat{\beta}(t)$
  - $\sqrt{n} (\hat{\beta}(t) - \text{bias}(\hat{\beta}(t)) - \beta(t))$ converges weakly to a mean-zero Gaussian process
  - Limiting covariance function of $\hat{\beta}(t)$
  - Consistency of the covariance estimator of $\hat{\beta}(t)$ via multiplier bootstrap

- **Estimators of individual functions:** bias of $\hat{b}_i(t)$

- **Estimator of covariance function of $b_i(t)$:** bias of $\hat{\xi}(s,t)$

---

## References

[1] Andersen, P. K., Borgan, O., Gill, R. D., & Keiding, N. (1993). *Statistical Models Based on Counting Processes*. New York: Springer.

[2] van der Vaart, A. W. & Wellner, J. A. (1996). *Weak Convergence and Empirical Processes*. New York: Springer.
